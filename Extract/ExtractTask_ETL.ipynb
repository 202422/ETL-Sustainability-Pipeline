{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c45e948-37b5-45d6-aafe-d672706913fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90caf5dc-87c0-4a72-bd71-f6a9917ee4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "API_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "needed_hours = 3000\n",
    "HOURLY_VARIABLES = [\n",
    "    \"temperature_2m\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"precipitation\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"weather_code\"\n",
    "]\n",
    "LOCATIONS = [\n",
    "    (48.8566, 2.3522),\n",
    "    (45.7640, 4.8357),\n",
    "    (43.2965, 5.3698),\n",
    "    (44.8378, -0.5792)\n",
    "]\n",
    "\n",
    "# Retry configuration for temporary HTTP errors\n",
    "session = requests.Session()\n",
    "retries = Retry(\n",
    "    total=3,  # Maximum number of attempts\n",
    "    backoff_factor=1,  # Exponential delay (1s, 2s, 4s)\n",
    "    status_forcelist=[429, 500, 502, 503, 504],  # HTTP status codes to retry on\n",
    "    allowed_methods=[\"GET\"]\n",
    ")\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe0343a-eebf-423f-aaf7-a78a25384e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch weather data\n",
    "def fetch_weather_data(latitude: float, longitude: float, needed_hours: int) -> pd.DataFrame:\n",
    "    all_data = []\n",
    "    remaining_hours = needed_hours\n",
    "    end_date = datetime.now()\n",
    "    \n",
    "    while remaining_hours > 0:\n",
    "        # Calculate the time range (maximum 90 days per API call)\n",
    "        chunk_days = min(90, (remaining_hours // 24) + 1)\n",
    "        start_date = end_date - timedelta(days=chunk_days)\n",
    "        \n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"start_date\": start_date.strftime('%Y-%m-%d'),\n",
    "            \"end_date\": end_date.strftime('%Y-%m-%d'),\n",
    "            \"hourly\": \",\".join(HOURLY_VARIABLES),\n",
    "            \"timezone\": \"Europe/Paris\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = session.get(API_URL, params=params, timeout=15)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP 4xx/5xx errors\n",
    "            \n",
    "            data = response.json()\n",
    "            if \"hourly\" not in data:\n",
    "                print(f\"No hourly data available for {latitude, longitude}\")\n",
    "                break\n",
    "                \n",
    "            chunk_df = pd.DataFrame(data[\"hourly\"])\n",
    "            \n",
    "            # Add metadata\n",
    "            chunk_df[\"latitude\"] = latitude\n",
    "            chunk_df[\"longitude\"] = longitude\n",
    "            \n",
    "            all_data.append(chunk_df)\n",
    "            fetched_hours = len(chunk_df)\n",
    "            remaining_hours -= fetched_hours\n",
    "            \n",
    "            print(f\"{fetched_hours} hourly records added for {latitude, longitude} (remaining: {remaining_hours})\")\n",
    "            \n",
    "            # Update for the next iteration\n",
    "            end_date = start_date - timedelta(days=1)\n",
    "            time.sleep(1)  # Respect API rate limits\n",
    "            \n",
    "            if fetched_hours == 0:\n",
    "                break\n",
    "                \n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            if response.status_code == 429:\n",
    "                print(f\"Rate limit reached for {latitude, longitude}. Waiting before retrying...\")\n",
    "                time.sleep(10)  # Longer wait time for status 429\n",
    "                continue\n",
    "            elif response.status_code == 404:\n",
    "                print(f\"Error 404: Invalid URL or parameters for {latitude, longitude}\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"HTTP error for {latitude, longitude}: {str(http_err)}\")\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Connection error for {latitude, longitude}: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    final_df = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "    return final_df.iloc[:3000]  # Return exactly the requested number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f171179-815c-49ce-b5ca-04e938246a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_locations(locations: list[tuple[float, float]], needed_hours: int) -> pd.DataFrame:\n",
    "    all_dfs = []\n",
    "    \n",
    "    for (lat, lon) in locations:\n",
    "        print(f\"\\n=== Fetching data for location ({lat}, {lon}) ===\")\n",
    "        \n",
    "        # Fetch data for this location\n",
    "        df_location = fetch_weather_data(latitude=lat, longitude=lon, needed_hours=needed_hours)\n",
    "        \n",
    "        if not df_location.empty:\n",
    "            all_dfs.append(df_location)\n",
    "        \n",
    "        # Pause between requests to avoid overloading the API\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Combine all DataFrames\n",
    "    final_df2 = pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Summary statistics\n",
    "    if not final_df2.empty:\n",
    "        counts = final_df2[\"latitude\"].value_counts()\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(f\"Total records retrieved: {len(final_df2)}\")\n",
    "        print(\"Breakdown by location:\")\n",
    "        print(counts.to_string())\n",
    "    \n",
    "    return final_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9f837d-cbad-431c-afaa-43a649a22891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fetching data for location (48.8566, 2.3522) ===\n",
      "2184 hourly records added for (48.8566, 2.3522) (remaining: 816)\n",
      "864 hourly records added for (48.8566, 2.3522) (remaining: -48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3708\\631658792.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fetching data for location (45.764, 4.8357) ===\n",
      "2184 hourly records added for (45.764, 4.8357) (remaining: 816)\n",
      "864 hourly records added for (45.764, 4.8357) (remaining: -48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3708\\631658792.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fetching data for location (43.2965, 5.3698) ===\n",
      "2184 hourly records added for (43.2965, 5.3698) (remaining: 816)\n",
      "864 hourly records added for (43.2965, 5.3698) (remaining: -48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3708\\631658792.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fetching data for location (44.8378, -0.5792) ===\n",
      "2184 hourly records added for (44.8378, -0.5792) (remaining: 816)\n",
      "864 hourly records added for (44.8378, -0.5792) (remaining: -48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3708\\631658792.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "Total records retrieved: 12000\n",
      "Breakdown by location:\n",
      "latitude\n",
      "48.8566    3000\n",
      "45.7640    3000\n",
      "43.2965    3000\n",
      "44.8378    3000\n"
     ]
    }
   ],
   "source": [
    "df_meteo = collect_all_locations(LOCATIONS, needed_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b2ec9b3-db43-4640-aba6-ffc3476a6cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   time                  12000 non-null  object \n",
      " 1   temperature_2m        7392 non-null   float64\n",
      " 2   relative_humidity_2m  7392 non-null   float64\n",
      " 3   precipitation         7392 non-null   float64\n",
      " 4   wind_speed_10m        7392 non-null   float64\n",
      " 5   weather_code          7392 non-null   float64\n",
      " 6   latitude              12000 non-null  float64\n",
      " 7   longitude             12000 non-null  float64\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 750.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_meteo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f7e4287-c11e-4c50-a02c-12bd687bb798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframe into csv format\n",
    "df_meteo.to_csv(\"weather_data_extracted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351565b-9c5d-4052-9330-5910a559d5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
